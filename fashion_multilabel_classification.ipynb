{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsrr0Kd2fB0WkbMLtuqV59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle keras-preprocessing\n",
        "!nvidia-smi -L"
      ],
      
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IdUsmVzm20H",
        "outputId": "d056e6cc-488c-4cc8-e71a-53f1180a96f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hGPU 0: Tesla T4 (UUID: GPU-b05279dd-124a-ad13-cb09-400605a96725)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.image as mat_img\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n"
      ],
      "metadata": {
        "id": "LL9zVfvZm46C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"fellahsamy\"\n",
        "os.environ['KAGGLE_KEY'] = \"236450079c9371bf4bac63b12dd62174\"\n",
        "\n",
        "\n",
        "def download_and_extract_kaggle_dataset(dataset_name, destination, unzip=True, quiet=False):\n",
        "    # Set up Kaggle API credentials\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    # Download the Kaggle dataset to the specified destination folder\n",
        "    api.dataset_download_files(dataset_name, path=destination, unzip=unzip, quiet=quiet)\n",
        "\n",
        "\n",
        "download_and_extract_kaggle_dataset('paramaggarwal/fashion-product-images-small', 'data/', unzip=True, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C7elJw9nARR",
        "outputId": "89e8c193-400b-4fda-c49c-bedce176f323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fashion-product-images-small.zip to data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 565M/565M [00:05<00:00, 100MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhSdoDUkmJZb",
        "outputId": "40969e9e-3151-4df6-f1c7-e0c516e5e879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading meta data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4443 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 15s 30ms/step - loss: 0.0743 - binary_accuracy: 0.9788 - recall: 0.6008 - precision: 0.5348\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.0348 - binary_accuracy: 0.9894 - recall: 0.7200 - precision: 0.7981\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4442 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.0431 - binary_accuracy: 0.9878 - recall: 0.6877 - precision: 0.7564\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.0289 - binary_accuracy: 0.9904 - recall: 0.7502 - precision: 0.8155\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4443 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.0379 - binary_accuracy: 0.9886 - recall: 0.7073 - precision: 0.7749\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.0267 - binary_accuracy: 0.9908 - recall: 0.7603 - precision: 0.8253\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4442 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.0363 - binary_accuracy: 0.9892 - recall: 0.7246 - precision: 0.7858\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.0255 - binary_accuracy: 0.9912 - recall: 0.7688 - precision: 0.8332\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4442 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.0348 - binary_accuracy: 0.9892 - recall: 0.7277 - precision: 0.7874\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.0235 - binary_accuracy: 0.9915 - recall: 0.7794 - precision: 0.8425\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4442 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.0336 - binary_accuracy: 0.9894 - recall: 0.7320 - precision: 0.7920\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.0232 - binary_accuracy: 0.9916 - recall: 0.7808 - precision: 0.8418\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4442 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.0338 - binary_accuracy: 0.9894 - recall: 0.7264 - precision: 0.7961\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.0235 - binary_accuracy: 0.9914 - recall: 0.7725 - precision: 0.8417\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4441 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.0308 - binary_accuracy: 0.9900 - recall: 0.7343 - precision: 0.8084\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.0224 - binary_accuracy: 0.9918 - recall: 0.7796 - precision: 0.8500\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4441 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.0309 - binary_accuracy: 0.9899 - recall: 0.7351 - precision: 0.8055\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.0228 - binary_accuracy: 0.9916 - recall: 0.7726 - precision: 0.8470\n",
            "Loading images...\n",
            "Preprocessing images...\n",
            "Preprocessing TF...\n",
            "Fitting model with 4441 lines...\n",
            "Epoch 1/2\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.0307 - binary_accuracy: 0.9900 - recall: 0.7384 - precision: 0.8088\n",
            "Epoch 2/2\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.0218 - binary_accuracy: 0.9919 - recall: 0.7832 - precision: 0.8520\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class FashionModel(tf.keras.Model):\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        super().__init__()\n",
        "        self.features_layer = tf.keras.applications.ResNet50(include_top = False, weights = 'imagenet', input_shape = input_shape, pooling='avg')\n",
        "        self.n_1_layer = tf.keras.layers.Dense(1024)\n",
        "        self.output_layer = tf.keras.layers.Dense(output_shape, activation ='sigmoid')\n",
        "        self.features_layer.trainable = False\n",
        "        \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        features = self.features_layer(inputs)\n",
        "        n_1_features = self.n_1_layer(features)\n",
        "        return self.output_layer(n_1_features)\n",
        "        \n",
        "def read_img(row):\n",
        "    \n",
        "    try:\n",
        "        path_imgs =\"./data/images\"\n",
        "        file_name = str(row['id'])+'.jpg'\n",
        "        file_name= os.path.join(path_imgs,file_name)\n",
        "        image = mat_img.imread(file_name)\n",
        "        row['image_shape'] = image.shape\n",
        "        row['image']=image\n",
        "    except FileNotFoundError as e:\n",
        "        row['image_shape'] = None\n",
        "        row['image']= None\n",
        "    return row\n",
        "\n",
        "def convert_single_chanel(df):\n",
        "    for index,image_info in df.iterrows():\n",
        "        if image_info.image.ndim == 2:\n",
        "            new_image = np.zeros(shape=(*image_info.image.shape,3),dtype=np.int_)\n",
        "            new_image[:,:,0]=image_info.image\n",
        "            new_image[:,:,1]=image_info.image\n",
        "            new_image[:,:,2]=image_info.image\n",
        "            image_info['image'] = new_image\n",
        "            image_info['image_shape'] = new_image.shape\n",
        "            df.loc[index]=image_info\n",
        "        \n",
        "    return df\n",
        "\n",
        "def resize_images(df):\n",
        "    for index,image_info in df.iterrows():\n",
        "        if image_info.image.shape != (80, 60, 3):\n",
        "            img_resized = tf.image.resize(image_info['image'],[80,60]).numpy().astype(np.int_)\n",
        "            image_info['image'] = img_resized\n",
        "            image_info['image_shape'] = img_resized.shape\n",
        "            df.loc[index]=image_info\n",
        "        \n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    categories_columns = ['gender','masterCategory','subCategory','articleType','baseColour','season']\n",
        "    meta_info = \"./data/styles.csv\"\n",
        "    print('Loading meta data...')\n",
        "    all_data =pd.read_csv(meta_info,on_bad_lines='skip') \n",
        "    all_data = pd.get_dummies(all_data, columns=categories_columns, prefix='cat_')\n",
        "    \n",
        "    # total number of labels ('gender','masterCategory',...) = 286 label\n",
        "    fashion_model = FashionModel(input_shape = (80,60,3),output_shape = 286)\n",
        "    fashion_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"binary_accuracy\",tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
        "    \n",
        "    \n",
        "    # charger les images en 10 fois pour eviter de surcharger la RAM\n",
        "    for sub_dataset in np.array_split(all_data, 10):\n",
        "        print('Loading images...')\n",
        "        data = sub_dataset.apply(read_img , axis=1)\n",
        "        data = data.dropna(subset=['image'])\n",
        "        print('Preprocessing images...')\n",
        "        data = convert_single_chanel(data)\n",
        "        data = resize_images(data)\n",
        "        y = data[[column for column in data.columns if column[0:4]=='cat_']]\n",
        "        x = data.image.to_list()\n",
        "        x = np.array(x)\n",
        "        print('Preprocessing TF...')\n",
        "        x = tf.keras.applications.resnet.preprocess_input(x) \n",
        "        print(f'Fitting model with {y.shape[0]} lines...')\n",
        "        fashion_model.fit(x=x, y=y, batch_size=48, epochs=2)\n"
      ]
    }
  ]
}
